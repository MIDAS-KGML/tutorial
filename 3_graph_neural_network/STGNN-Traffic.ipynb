{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94334c34-bf03-416e-9de3-eb6898997273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sciclone/home/hjiang16/.conda/envs/gnn_gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DataLoader_METR_LA:\n",
    "    \"\"\"\n",
    "    Optimized DataLoader for the METR-LA traffic speed dataset\n",
    "    Loads continuous time series where each time step's output is the input for the next time step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path, batch_size, test_batch_size=None,\n",
    "                 seq_length=12, normalize=True):\n",
    "        self.data_path = data_path\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = test_batch_size or batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.normalize = normalize\n",
    "\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        # Load speed data\n",
    "        df = pd.read_hdf(os.path.join(self.data_path, 'METR-LA.h5'))\n",
    "        values = df.values  # shape: [time, nodes]\n",
    "        self.num_nodes = values.shape[1]\n",
    "        print(f\"[Data] Loaded speed matrix: {values.shape}\")\n",
    "\n",
    "        # Load adjacency matrix\n",
    "        adj_file = 'adj_METR-LA.pkl'\n",
    "        if not os.path.exists(os.path.join(self.data_path, adj_file)):\n",
    "            adj_file = 'adj_mx.pkl'\n",
    "\n",
    "        print(f\"[Graph] Loading adjacency matrix from: {adj_file}\")\n",
    "        with open(os.path.join(self.data_path, adj_file), 'rb') as f:\n",
    "            adj_data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "        # Handle different formats of adjacency matrix data\n",
    "        if isinstance(adj_data, (list, tuple)) and len(adj_data) == 3:\n",
    "            _, _, adj_mx = adj_data\n",
    "        else:\n",
    "            adj_mx = adj_data[-1] if isinstance(adj_data, (list, tuple)) else adj_data\n",
    "\n",
    "        # Ensure the adjacency matrix is a 2D dense matrix\n",
    "        adj_mx = np.array(adj_mx)\n",
    "        if adj_mx.ndim > 2:\n",
    "            adj_mx = adj_mx[0]\n",
    "        print(f\"[Graph] Adjacency shape: {adj_mx.shape}\")\n",
    "\n",
    "        # Convert to PyTorch Geometric format\n",
    "        adj_coo = sp.coo_matrix(adj_mx)\n",
    "        indices = np.vstack((adj_coo.row, adj_coo.col))\n",
    "        self.edge_index = torch.LongTensor(indices)\n",
    "        self.edge_weight = torch.FloatTensor(adj_coo.data)\n",
    "\n",
    "        # Data normalization\n",
    "        if self.normalize:\n",
    "            self.mean = np.mean(values)\n",
    "            self.std = np.std(values)\n",
    "            values = (values - self.mean) / self.std\n",
    "        else:\n",
    "            self.mean, self.std = 0, 1\n",
    "\n",
    "        # Dataset split (70/10/20)\n",
    "        num_samples = len(values)\n",
    "        num_train = int(num_samples * 0.7)\n",
    "        num_test = int(num_samples * 0.2)\n",
    "        num_val = num_samples - num_train - num_test\n",
    "\n",
    "        train_data = values[:num_train]\n",
    "        val_data = values[num_train:num_train + num_val]\n",
    "        test_data = values[num_train + num_val:]\n",
    "\n",
    "        print(f\"[Split] Train: {train_data.shape}, Val: {val_data.shape}, Test: {test_data.shape}\")\n",
    "\n",
    "        # Create PyTorch datasets and data loaders\n",
    "        self.train_dataset = METR_LA_Dataset(train_data, self.seq_length)\n",
    "        self.val_dataset = METR_LA_Dataset(val_data, self.seq_length)\n",
    "        self.test_dataset = METR_LA_Dataset(test_data, self.seq_length)\n",
    "\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
    "                                       shuffle=True, drop_last=True)\n",
    "        self.val_loader = DataLoader(self.val_dataset, batch_size=self.test_batch_size,\n",
    "                                     shuffle=False, drop_last=True)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=self.test_batch_size,\n",
    "                                      shuffle=False, drop_last=True)\n",
    "\n",
    "    def get_loaders(self):\n",
    "        return (self.train_loader, self.val_loader, self.test_loader,\n",
    "                self.edge_index, self.edge_weight, self.mean, self.std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7893fb23-0827-45b2-b647-63c6b947d9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class METR_LA_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Optimized METR-LA dataset class\n",
    "    Each sample is a continuous window of length seq_length, including input and target\n",
    "    x1, x2, ..., x_{seq_length} as input\n",
    "    x2, x3, ..., x_{seq_length+1} as target\n",
    "    \"\"\"\n",
    "    def __init__(self, data, seq_length):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "        # We need one more time step than the sequence length (for the label)\n",
    "        self.num_samples = len(data) - seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get window of length seq_length+1\n",
    "        time_window = self.data[idx : idx + self.seq_length + 1]\n",
    "\n",
    "        # Swap time and node dimensions to form [num_nodes, total_time_steps]\n",
    "        time_window = np.transpose(time_window, (1, 0))\n",
    "\n",
    "        # Separate input sequence and target sequence (target is input shifted by one step)\n",
    "        # Input: x1, x2, ..., x_{seq_length}\n",
    "        x_seq = time_window[:, :-1]\n",
    "        # Target: x2, x3, ..., x_{seq_length+1}\n",
    "        y_target = time_window[:, 1:]\n",
    "\n",
    "        # Add feature dimension, convert to tensor\n",
    "        x_seq = torch.FloatTensor(x_seq).unsqueeze(-1)  # [num_nodes, seq_length, 1]\n",
    "        y_target = torch.FloatTensor(y_target)          # [num_nodes, seq_length]\n",
    "\n",
    "        return x_seq, y_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe769c5-038d-4acc-8361-3a93d6ba6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mse_loss(preds, labels):\n",
    "    \"\"\"Mean squared error loss\"\"\"\n",
    "    return torch.mean((preds - labels) ** 2)\n",
    "\n",
    "def mae_loss(preds, labels):\n",
    "    \"\"\"Mean absolute error loss\"\"\"\n",
    "    return torch.mean(torch.abs(preds - labels))\n",
    "\n",
    "def rmse_loss(preds, labels):\n",
    "    \"\"\"Root mean squared error loss\"\"\"\n",
    "    return torch.sqrt(mse_loss(preds, labels))\n",
    "\n",
    "def metric(preds, labels):\n",
    "    \"\"\"Calculate multiple evaluation metrics\"\"\"\n",
    "    mse_val = mse_loss(preds, labels).item()\n",
    "    mae_val = mae_loss(preds, labels).item()\n",
    "    rmse_val = rmse_loss(preds, labels).item()\n",
    "    return mse_val, mae_val, rmse_val\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device, edge_index, edge_weight, epoch):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch}\") as t:\n",
    "        for i, (x_seq, y_target) in enumerate(t):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prepare input data\n",
    "            x_seq = x_seq.to(device)        # [batch_size, num_nodes, seq_length, 1]\n",
    "            y_target = y_target.to(device)  # [batch_size, num_nodes, seq_length]\n",
    "            edge_index = edge_index.to(device)\n",
    "            if edge_weight is not None:\n",
    "                edge_weight = edge_weight.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(x_seq, edge_index, edge_weight)  # [batch_size, num_nodes, seq_length]\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(y_pred, y_target)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            total_loss += loss.item()\n",
    "            t.set_postfix(loss=total_loss / (i + 1))\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, device, edge_index, edge_weight):\n",
    "    \"\"\"Evaluate model on validation or test set\"\"\"\n",
    "    model.eval()\n",
    "    mse_sum, mae_sum, rmse_sum = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_seq, y_target in data_loader:\n",
    "            # Prepare input data\n",
    "            x_seq = x_seq.to(device)        # [batch_size, num_nodes, seq_length, 1]\n",
    "            y_target = y_target.to(device)  # [batch_size, num_nodes, seq_length]\n",
    "            edge_index = edge_index.to(device)\n",
    "            if edge_weight is not None:\n",
    "                edge_weight = edge_weight.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(x_seq, edge_index, edge_weight)  # [batch_size, num_nodes, seq_length]\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            mse_val, mae_val, rmse_val = metric(y_pred, y_target)\n",
    "            mse_sum += mse_val\n",
    "            mae_sum += mae_val\n",
    "            rmse_sum += rmse_val\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    return (\n",
    "        mse_sum / num_batches,\n",
    "        mae_sum / num_batches,\n",
    "        rmse_sum / num_batches\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_future_steps(model, data_loader, device, edge_index, edge_weight, future_steps=3):\n",
    "    \"\"\"Evaluate multi-step future prediction\"\"\"\n",
    "    model.eval()\n",
    "    mse_sum, mae_sum, rmse_sum = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_seq, y_target in data_loader:\n",
    "            # Prepare input data\n",
    "            x_seq = x_seq.to(device)        # [batch_size, num_nodes, seq_length, 1]\n",
    "            y_target = y_target.to(device)  # [batch_size, num_nodes, seq_length]\n",
    "            edge_index = edge_index.to(device)\n",
    "            if edge_weight is not None:\n",
    "                edge_weight = edge_weight.to(device)\n",
    "\n",
    "            # Use x_seq as historical data, predict future_steps steps ahead\n",
    "            y_pred = model.predict_future_steps(\n",
    "                x_seq, edge_index, edge_weight, future_steps\n",
    "            )  # [batch_size, num_nodes, future_steps]\n",
    "\n",
    "            # Get the true future values for the next future_steps from complete target\n",
    "            true_future = y_target[:, :, :future_steps]\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            mse_val, mae_val, rmse_val = metric(y_pred, true_future)\n",
    "            mse_sum += mse_val\n",
    "            mae_sum += mae_val\n",
    "            rmse_sum += rmse_val\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    return (\n",
    "        mse_sum / num_batches,\n",
    "        mae_sum / num_batches,\n",
    "        rmse_sum / num_batches\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73856867-41c2-4ec7-b36f-842843900076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNNLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Neural Network layer for spatial feature extraction\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.1, use_gat=False):\n",
    "        super(GNNLayer, self).__init__()\n",
    "\n",
    "        self.use_gat = use_gat\n",
    "\n",
    "        if use_gat:\n",
    "            # GAT version\n",
    "            self.conv = GATConv(in_channels, out_channels, heads=1, dropout=dropout)\n",
    "        else:\n",
    "            # GCN version\n",
    "            self.conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "        self.norm = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        \"\"\"\n",
    "        x: node features [batch_size*num_nodes, in_channels]\n",
    "        edge_index: edge indices [2, num_edges]\n",
    "        edge_weight: edge weights [num_edges]\n",
    "        \"\"\"\n",
    "        if self.use_gat:\n",
    "            # GAT doesn't use edge_weight\n",
    "            x = self.conv(x, edge_index)\n",
    "        else:\n",
    "            # GCN uses edge_weight\n",
    "            x = self.conv(x, edge_index, edge_weight)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class RNNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    RNN/GRU/LSTM block for temporal feature extraction and hidden state propagation\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, rnn_type='gru', dropout=0.1):\n",
    "        super(RNNBlock, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.rnn_type = rnn_type.lower()\n",
    "\n",
    "        # Choose RNN type\n",
    "        if self.rnn_type == 'gru':\n",
    "            self.rnn_cell = nn.GRUCell(input_dim, hidden_dim)\n",
    "        elif self.rnn_type == 'lstm':\n",
    "            self.rnn_cell = nn.LSTMCell(input_dim, hidden_dim)\n",
    "        else:\n",
    "            self.rnn_cell = nn.RNNCell(input_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        x: current time step features [batch_size*num_nodes, input_dim]\n",
    "        h_prev: previous time step hidden state\n",
    "               - GRU/RNN: [batch_size*num_nodes, hidden_dim]\n",
    "               - LSTM: tuple of two tensors\n",
    "        \"\"\"\n",
    "        # Handle hidden state based on RNN type\n",
    "        if self.rnn_type == 'lstm':\n",
    "            h_prev_h, h_prev_c = h_prev\n",
    "            h_new, c_new = self.rnn_cell(x, (h_prev_h, h_prev_c))\n",
    "            h_new = self.dropout(h_new)\n",
    "            return (h_new, c_new)\n",
    "        else:\n",
    "            h_new = self.rnn_cell(x, h_prev)\n",
    "            h_new = self.dropout(h_new)\n",
    "            return h_new\n",
    "\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-layer perceptron predictor for generating predictions from RNN output\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=3, dropout=0.1):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "\n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        self.norms.append(nn.LayerNorm(hidden_dim))\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.norms.append(nn.LayerNorm(hidden_dim))\n",
    "\n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: RNN output [batch_size*num_nodes, input_dim]\n",
    "        \"\"\"\n",
    "        # Process hidden layers\n",
    "        for i, (layer, norm) in enumerate(zip(self.layers[:-1], self.norms)):\n",
    "            x = layer(x)\n",
    "            x = norm(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class STGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-Temporal Graph Neural Network, strictly implemented according to the architecture\n",
    "    For time series x1, x2, ..., xT:\n",
    "    1. Time step t: xt → GNN → RNN(ht-1) → ht → MLP → prediction x(t+1)\n",
    "    2. Hidden state of each time step is passed to the next time step\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_nodes,\n",
    "                 node_features,\n",
    "                 hidden_dim,\n",
    "                 seq_length,\n",
    "                 gnn_type='gcn',\n",
    "                 rnn_type='gru',\n",
    "                 dropout=0.1):\n",
    "        super(STGNN, self).__init__()\n",
    "\n",
    "        self.num_nodes = num_nodes\n",
    "        self.node_features = node_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.seq_length = seq_length\n",
    "        self.gnn_type = gnn_type.lower()\n",
    "        self.rnn_type = rnn_type.lower()\n",
    "\n",
    "        # GNN layer - for spatial feature extraction\n",
    "        self.gnn = GNNLayer(\n",
    "            in_channels=node_features,\n",
    "            hidden_channels=hidden_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            use_gat=(gnn_type == 'gat')\n",
    "        )\n",
    "\n",
    "        # RNN/GRU/LSTM block - for temporal feature extraction\n",
    "        self.rnn_block = RNNBlock(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            rnn_type=rnn_type,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # MLP predictor - to predict next time step based on hidden state\n",
    "        self.predictor = MLPPredictor(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=1,  # single-step prediction\n",
    "            num_layers=2,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def _init_hidden_state(self, batch_size, device):\n",
    "        \"\"\"Initialize RNN hidden state\"\"\"\n",
    "        if self.rnn_type == 'lstm':\n",
    "            return (torch.zeros(batch_size * self.num_nodes, self.hidden_dim).to(device),\n",
    "                    torch.zeros(batch_size * self.num_nodes, self.hidden_dim).to(device))\n",
    "        else:\n",
    "            return torch.zeros(batch_size * self.num_nodes, self.hidden_dim).to(device)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        \"\"\"\n",
    "        Training mode: train on the entire input sequence, predict each subsequent time step\n",
    "\n",
    "        x: input sequence [batch_size, num_nodes, seq_length, node_features]\n",
    "        edge_index: graph edge index [2, num_edges]\n",
    "        edge_weight: edge weights [num_edges]\n",
    "\n",
    "        returns: predictions for all time steps [batch_size, num_nodes, seq_length]\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        device = x.device\n",
    "\n",
    "        # Store predictions for all time steps\n",
    "        predictions = []\n",
    "\n",
    "        # Initialize RNN hidden state\n",
    "        h = self._init_hidden_state(batch_size, device)\n",
    "\n",
    "        # Process each time step\n",
    "        for t in range(self.seq_length):\n",
    "            # Extract current time step graph data [batch_size, num_nodes, node_features]\n",
    "            x_t = x[:, :, t, :]\n",
    "\n",
    "            # Reshape to [batch_size * num_nodes, node_features] for GNN\n",
    "            x_t_flat = x_t.reshape(batch_size * self.num_nodes, -1)\n",
    "\n",
    "            # a. Spatial feature extraction through GNN (corresponding to GNN layers in architecture)\n",
    "            gnn_out = self.gnn(x_t_flat, edge_index, edge_weight)  # [batch_size * num_nodes, hidden_dim]\n",
    "\n",
    "            # b. Temporal feature extraction through RNN (corresponding to RNN/GRU/LSTM block in architecture)\n",
    "            h = self.rnn_block(gnn_out, h)\n",
    "\n",
    "            # c. Predict next time step based on current hidden state (corresponding to MLP in architecture)\n",
    "            if self.rnn_type == 'lstm':\n",
    "                pred_input = h[0]  # For LSTM, use h not c\n",
    "            else:\n",
    "                pred_input = h\n",
    "\n",
    "            # Generate prediction through MLP\n",
    "            pred = self.predictor(pred_input)  # [batch_size * num_nodes, 1]\n",
    "            pred = pred.reshape(batch_size, self.num_nodes)  # [batch_size, num_nodes]\n",
    "\n",
    "            # Store current time step prediction\n",
    "            predictions.append(pred)\n",
    "\n",
    "        # Stack all time step predictions [batch_size, num_nodes, seq_length]\n",
    "        predictions = torch.stack(predictions, dim=2)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict_future_steps(self, x_history, edge_index, edge_weight=None, future_steps=3):\n",
    "        \"\"\"\n",
    "        Test mode: autoregressive prediction of multiple future steps using historical data\n",
    "\n",
    "        x_history: historical data [batch_size, num_nodes, history_length, node_features]\n",
    "        edge_index: graph edge index [2, num_edges]\n",
    "        edge_weight: edge weights [num_edges]\n",
    "        future_steps: number of future steps to predict\n",
    "\n",
    "        returns: predictions for future time steps [batch_size, num_nodes, future_steps]\n",
    "        \"\"\"\n",
    "        batch_size = x_history.size(0)\n",
    "        device = x_history.device\n",
    "\n",
    "        # First establish hidden state using historical data\n",
    "        h = self._init_hidden_state(batch_size, device)\n",
    "\n",
    "        # Process all historical time steps\n",
    "        history_length = x_history.size(2)\n",
    "        for t in range(history_length):\n",
    "            x_t = x_history[:, :, t, :]\n",
    "            x_t_flat = x_t.reshape(batch_size * self.num_nodes, -1)\n",
    "            gnn_out = self.gnn(x_t_flat, edge_index, edge_weight)\n",
    "            h = self.rnn_block(gnn_out, h)\n",
    "\n",
    "        # Start predicting future steps from the last historical point\n",
    "        future_predictions = []\n",
    "        current_input = x_history[:, :, -1, :]  # Last historical point\n",
    "\n",
    "        # Autoregressive prediction of future steps\n",
    "        for _ in range(future_steps):\n",
    "            # 1. Prepare current input\n",
    "            current_input_flat = current_input.reshape(batch_size * self.num_nodes, -1)\n",
    "\n",
    "            # 2. Process through GNN\n",
    "            gnn_out = self.gnn(current_input_flat, edge_index, edge_weight)\n",
    "\n",
    "            # 3. Update hidden state\n",
    "            h = self.rnn_block(gnn_out, h)\n",
    "\n",
    "            # 4. Generate prediction\n",
    "            if self.rnn_type == 'lstm':\n",
    "                pred_input = h[0]\n",
    "            else:\n",
    "                pred_input = h\n",
    "\n",
    "            pred = self.predictor(pred_input)  # [batch_size * num_nodes, 1]\n",
    "            pred = pred.reshape(batch_size, self.num_nodes)  # [batch_size, num_nodes]\n",
    "\n",
    "            # 5. Save prediction\n",
    "            future_predictions.append(pred)\n",
    "\n",
    "            # 6. Use current prediction as input for next step\n",
    "            current_input = pred.unsqueeze(-1)  # [batch_size, num_nodes, 1]\n",
    "\n",
    "        # Stack all future predictions [batch_size, num_nodes, future_steps]\n",
    "        future_predictions = torch.stack(future_predictions, dim=2)\n",
    "\n",
    "        return future_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15e596f4-3ddd-4fb7-9b7d-4f8b1ac3080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mse_loss(preds, labels):\n",
    "    \"\"\"Mean squared error loss\"\"\"\n",
    "    return torch.mean((preds - labels) ** 2)\n",
    "\n",
    "def mae_loss(preds, labels):\n",
    "    \"\"\"Mean absolute error loss\"\"\"\n",
    "    return torch.mean(torch.abs(preds - labels))\n",
    "\n",
    "def rmse_loss(preds, labels):\n",
    "    \"\"\"Root mean squared error loss\"\"\"\n",
    "    return torch.sqrt(mse_loss(preds, labels))\n",
    "\n",
    "def metric(preds, labels):\n",
    "    \"\"\"Calculate multiple evaluation metrics\"\"\"\n",
    "    mse_val = mse_loss(preds, labels).item()\n",
    "    mae_val = mae_loss(preds, labels).item()\n",
    "    rmse_val = rmse_loss(preds, labels).item()\n",
    "    return mse_val, mae_val, rmse_val\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device, edge_index, edge_weight, epoch):\n",
    "    \"\"\"Train model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch}\") as t:\n",
    "        for i, (x_seq, y_target) in enumerate(t):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Prepare input data\n",
    "            x_seq = x_seq.to(device)        # [batch_size, num_nodes, seq_length, 1]\n",
    "            y_target = y_target.to(device)  # [batch_size, num_nodes, seq_length]\n",
    "            edge_index = edge_index.to(device)\n",
    "            if edge_weight is not None:\n",
    "                edge_weight = edge_weight.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(x_seq, edge_index, edge_weight)  # [batch_size, num_nodes, seq_length]\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(y_pred, y_target)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            total_loss += loss.item()\n",
    "            t.set_postfix(loss=total_loss / (i + 1))\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, device, edge_index, edge_weight):\n",
    "    \"\"\"Evaluate model on validation or test set\"\"\"\n",
    "    model.eval()\n",
    "    mse_sum, mae_sum, rmse_sum = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_seq, y_target in data_loader:\n",
    "            # Prepare input data\n",
    "            x_seq = x_seq.to(device)        # [batch_size, num_nodes, seq_length, 1]\n",
    "            y_target = y_target.to(device)  # [batch_size, num_nodes, seq_length]\n",
    "            edge_index = edge_index.to(device)\n",
    "            if edge_weight is not None:\n",
    "                edge_weight = edge_weight.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(x_seq, edge_index, edge_weight)  # [batch_size, num_nodes, seq_length]\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            mse_val, mae_val, rmse_val = metric(y_pred, y_target)\n",
    "            mse_sum += mse_val\n",
    "            mae_sum += mae_val\n",
    "            rmse_sum += rmse_val\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    return (\n",
    "        mse_sum / num_batches,\n",
    "        mae_sum / num_batches,\n",
    "        rmse_sum / num_batches\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_future_steps(model, data_loader, device, edge_index, edge_weight, future_steps=3):\n",
    "    \"\"\"Evaluate multi-step future prediction\"\"\"\n",
    "    model.eval()\n",
    "    mse_sum, mae_sum, rmse_sum = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_seq, y_target in data_loader:\n",
    "            # Prepare input data\n",
    "            x_seq = x_seq.to(device)        # [batch_size, num_nodes, seq_length, 1]\n",
    "            y_target = y_target.to(device)  # [batch_size, num_nodes, seq_length]\n",
    "            edge_index = edge_index.to(device)\n",
    "            if edge_weight is not None:\n",
    "                edge_weight = edge_weight.to(device)\n",
    "\n",
    "            # Use x_seq as historical data, predict future_steps steps ahead\n",
    "            y_pred = model.predict_future_steps(\n",
    "                x_seq, edge_index, edge_weight, future_steps\n",
    "            )  # [batch_size, num_nodes, future_steps]\n",
    "\n",
    "            # Get the true future values for the next future_steps from complete target\n",
    "            true_future = y_target[:, :, :future_steps]\n",
    "\n",
    "            # Calculate evaluation metrics\n",
    "            mse_val, mae_val, rmse_val = metric(y_pred, true_future)\n",
    "            mse_sum += mse_val\n",
    "            mae_sum += mae_val\n",
    "            rmse_sum += rmse_val\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    return (\n",
    "        mse_sum / num_batches,\n",
    "        mae_sum / num_batches,\n",
    "        rmse_sum / num_batches\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57db71a2-26dc-4b6e-ba8a-b465adaeb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_stgnn(\n",
    "    data_path='.',\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    lr=0.001,\n",
    "    seq_length=12,\n",
    "    future_steps=3,  # Predict future steps during testing\n",
    "    hidden_dim=64,\n",
    "    gnn_type='gcn',  # 'gcn' or 'gat'\n",
    "    rnn_type='gru',  # 'rnn', 'gru', or 'lstm'\n",
    "    dropout=0.1,\n",
    "    use_cuda=True,\n",
    "    seed=42,\n",
    "    save_model=True,\n",
    "    save_path='models'\n",
    "):\n",
    "    \"\"\"Complete training pipeline for STGNN\"\"\"\n",
    "    # Set random seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    device = torch.device('cuda' if use_cuda and torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    print(f\"Training device: {device}\")\n",
    "    print(f\"Model configuration: GNN={gnn_type}, RNN={rnn_type}, hidden_dim={hidden_dim}\")\n",
    "\n",
    "    # Load dataset\n",
    "    data_loader = DataLoader_METR_LA(\n",
    "        data_path, batch_size, seq_length=seq_length\n",
    "    )\n",
    "    train_loader, val_loader, test_loader, edge_index, edge_weight, mean, std = data_loader.get_loaders()\n",
    "\n",
    "    # Initialize model\n",
    "    model = STGNN(\n",
    "        num_nodes=207,        # METR-LA has 207 sensors\n",
    "        node_features=1,      # Input feature dimension\n",
    "        hidden_dim=hidden_dim,\n",
    "        seq_length=seq_length,\n",
    "        gnn_type=gnn_type,\n",
    "        rnn_type=rnn_type,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    # Set optimizer and learning rate scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "\n",
    "    # Use MAE as the main loss function\n",
    "    criterion = mae_loss\n",
    "\n",
    "    # Create model save directory\n",
    "    if save_model and not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Training loop variables\n",
    "    best_val_mae = float('inf')\n",
    "    best_model_state = None\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_metrics = []\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train for one epoch\n",
    "        train_loss = train(\n",
    "            model, train_loader, optimizer, criterion,\n",
    "            device, edge_index, edge_weight, epoch\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_mse, val_mae, val_rmse = evaluate(\n",
    "            model, val_loader, device, edge_index, edge_weight\n",
    "        )\n",
    "        val_losses.append(val_mae)\n",
    "        val_metrics.append((val_mse, val_mae, val_rmse))\n",
    "\n",
    "        # Adjust learning rate based on validation MAE\n",
    "        scheduler.step(val_mae)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val MSE: {val_mse:.4f} | MAE: {val_mae:.4f} | RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "        # Evaluate multi-step future prediction every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            future_mse, future_mae, future_rmse = evaluate_future_steps(\n",
    "                model, val_loader, device, edge_index, edge_weight, future_steps\n",
    "            )\n",
    "            print(f\"Future {future_steps} steps prediction: MSE: {future_mse:.4f} | MAE: {future_mae:.4f} | RMSE: {future_rmse:.4f}\")\n",
    "\n",
    "        # Save the best model based on validation MAE\n",
    "        if val_mae < best_val_mae:\n",
    "            best_val_mae = val_mae\n",
    "            if save_model:\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                torch.save(\n",
    "                    best_model_state,\n",
    "                    os.path.join(save_path, f'best_stgnn_{gnn_type}_{rnn_type}.pth')\n",
    "                )\n",
    "                print(f\"New best model saved! (Val MAE: {val_mae:.4f})\")\n",
    "\n",
    "    # Plot training progress\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss (MAE)')\n",
    "    plt.plot(val_losses, label='Val MAE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss / MAE')\n",
    "    plt.title(f'Training Progress ({gnn_type.upper()}-{rnn_type.upper()})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot([m[0] for m in val_metrics], label='Val MSE')\n",
    "    plt.plot([m[1] for m in val_metrics], label='Val MAE')\n",
    "    plt.plot([m[2] for m in val_metrics], label='Val RMSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title('Validation Metrics')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_model:\n",
    "        plt.savefig(os.path.join(save_path, f'stgnn_{gnn_type}_{rnn_type}_training.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # Load the best saved model for testing\n",
    "    if save_model and best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model for testing\")\n",
    "\n",
    "    # Evaluate one-step prediction on test set\n",
    "    print(\"\\nEvaluating next-step prediction on test set...\")\n",
    "    test_mse, test_mae, test_rmse = evaluate(\n",
    "        model, test_loader, device, edge_index, edge_weight\n",
    "    )\n",
    "    print(f\"[STGNN {gnn_type.upper()}-{rnn_type.upper()}] Test Results (Next Step) → MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "    # Evaluate multi-step future prediction on test set\n",
    "    print(f\"\\nEvaluating future {future_steps} steps prediction on test set...\")\n",
    "    future_mse, future_mae, future_rmse = evaluate_future_steps(\n",
    "        model, test_loader, device, edge_index, edge_weight, future_steps\n",
    "    )\n",
    "    print(f\"[STGNN {gnn_type.upper()}-{rnn_type.upper()}] Test Results (Future {future_steps} Steps) → MSE: {future_mse:.4f}, MAE: {future_mae:.4f}, RMSE: {future_rmse:.4f}\")\n",
    "\n",
    "    return model, (test_mse, test_mae, test_rmse), (future_mse, future_mae, future_rmse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d72e11fe-38bc-41d6-8bfb-6721c623f365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda\n",
      "Model configuration: GNN=gcn, RNN=gru, hidden_dim=64\n",
      "[Data] Loaded speed matrix: (34272, 207)\n",
      "[Graph] Loading adjacency matrix from: adj_mx.pkl\n",
      "[Graph] Adjacency shape: (207, 207)\n",
      "[Split] Train: (23990, 207), Val: (3428, 207), Test: (6854, 207)\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  36%|███▌      | 134/374 [00:11<00:21, 11.31it/s, loss=0.246]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model and get necessary variables for visualization\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, (test_mse, test_mae, test_rmse), (future_mse, future_mae, future_rmse) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_stgnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgnn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgcn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrnn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgru\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 68\u001b[0m, in \u001b[0;36mtrain_stgnn\u001b[0;34m(data_path, batch_size, epochs, lr, seq_length, future_steps, hidden_dim, gnn_type, rnn_type, dropout, use_cuda, seed, save_model, save_path)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, device, edge_index, edge_weight, epoch)\u001b[0m\n\u001b[1;32m     35\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m edge_weight\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size, num_nodes, seq_length]\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y_target)\n",
      "File \u001b[0;32m/sciclone/home/hjiang16/.conda/envs/gnn_gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 207\u001b[0m, in \u001b[0;36mSTGNN.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    204\u001b[0m x_t_flat \u001b[38;5;241m=\u001b[39m x_t\u001b[38;5;241m.\u001b[39mreshape(batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_nodes, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# a. Spatial feature extraction through GNN (corresponding to GNN layers in architecture)\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m gnn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch_size * num_nodes, hidden_dim]\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# b. Temporal feature extraction through RNN (corresponding to RNN/GRU/LSTM block in architecture)\u001b[39;00m\n\u001b[1;32m    210\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn_block(gnn_out, h)\n",
      "File \u001b[0;32m/sciclone/home/hjiang16/.conda/envs/gnn_gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mGNNLayer.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x, edge_index)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# GCN uses edge_weight\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m     35\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n",
      "File \u001b[0;32m/sciclone/home/hjiang16/.conda/envs/gnn_gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/sciclone/home/hjiang16/.conda/envs/gnn_gpu/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m/sciclone/home/hjiang16/.conda/envs/gnn_gpu/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/sciclone/home/hjiang16/.conda/envs/gnn_gpu/lib/python3.10/site-packages/torch_geometric/utils/loop.py:643\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    640\u001b[0m     inv_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mmask\n\u001b[1;32m    641\u001b[0m     loop_attr[edge_index[\u001b[38;5;241m0\u001b[39m][inv_mask]] \u001b[38;5;241m=\u001b[39m edge_attr[inv_mask]\n\u001b[0;32m--> 643\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_attr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m is_undirected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model and get necessary variables for visualization\n",
    "model, (test_mse, test_mae, test_rmse), (future_mse, future_mae, future_rmse) = train_stgnn(\n",
    "    data_path='./',\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    hidden_dim=64,\n",
    "    seq_length=12,\n",
    "    future_steps=1,\n",
    "    gnn_type='gcn',\n",
    "    rnn_type='gru',\n",
    "    dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78d4a4-dd4d-477b-94f4-c40bbf08fe70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_gpu",
   "language": "python",
   "name": "gnn_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
